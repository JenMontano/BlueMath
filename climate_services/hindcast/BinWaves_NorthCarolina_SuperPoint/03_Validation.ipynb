{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BinWaves example in Cantabria (Validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BinWaves Notebooks Overview\n",
    "\n",
    "This Jupyter Notebook is the first of three in the **BinWaves** modeling workflow, following Cagigal et al., 2024 :\n",
    "\n",
    "1. `BinWaves_Propagation.ipynb`  \n",
    "2. `BinWaves_Reconstruction.ipynb`  \n",
    "3. `BinWaves_Validation.ipynb`\n",
    "\n",
    "---\n",
    "\n",
    "#### Before You Start\n",
    "\n",
    "Make sure you have:\n",
    "\n",
    "- Installed the latest version of `bluemath-tk`:  \n",
    "  ```bash\n",
    "  pip install bluemath-tk\n",
    "\n",
    "Before continuing, ensure you have **created and activated a Python environment**.\n",
    "\n",
    "*** Other Required Packages ***\n",
    "- `wavespectra` \n",
    "- `cartophy`\n",
    " \n",
    "---\n",
    "\n",
    "<details>\n",
    "<summary><strong>üìÅ BinWaves_Propagation.ipynb</strong></summary>\n",
    "\n",
    "This notebook constructs the **library of pre-run cases** for all **monochromatic wave systems**.\n",
    "\n",
    "##### Requirements:\n",
    "\n",
    "- A **bathymetry** file placed in the `outputs/` folder, in the correct format.\n",
    "\n",
    "If you don't have a specific bathymetry file for your study area, you can:\n",
    "\n",
    "- **Download GEBCO bathymetry data** (~400‚ÄØm resolution):  [https://download.gebco.net/](https://download.gebco.net/)\n",
    "\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "<details>\n",
    "<summary><strong>üìÅ BinWaves_Reconstruction.ipynb</strong></summary>\n",
    "\n",
    "This notebook reconstructs **wave conditions** using **offshore directional wave spectra**.\n",
    "\n",
    "##### Requirements:\n",
    "\n",
    "- Offshore wave spectrum data (e.g., **CAWCR** or **ERA5** datasets).\n",
    "  - CAWCR spectra can be downloaded using a helper script (e.g., Javi's code?).\n",
    "\n",
    "- **NOTE**: Optionally, apply **satellite corrections** to the hindcast spectrum before running BinWaves using the `CalVal` notebook, which handles the required format conversions.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "<details open>\n",
    "<summary><strong>üìÅ BinWaves_Validation.ipynb</strong></summary>\n",
    "\n",
    "This notebook performs **validation** using **wave buoy data**, if available.\n",
    "\n",
    "##### Requirements:\n",
    "\n",
    "- Wave buoy data in a format compatible with BinWaves (if available).\n",
    "- Some wave buoy data can be freely downloaded from:  \n",
    "  üåä [https://www.ndbc.noaa.gov/](https://www.ndbc.noaa.gov/)\n",
    "\n",
    "- **NOTE:** You can use the `NDBC_buoy_data.ipynb` notebook to:\n",
    "  - Download the buoy data.\n",
    "  - Convert it into the appropriate format for BinWaves.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buoy 41013 coordinates:\n",
      "WGS84: -77.764, 33.441\n",
      "\n",
      "Selected kp_coeffs site coordinates:\n",
      "[-77.764], [33.441]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# Define buoy locations dictionary with both UTM and WGS84 coordinates\n",
    "# if not buoys available  just run plot_selected_bathy(bathy=bathy)\n",
    "buoys = {\n",
    "    \"44088\": (-74.8390, 36.6120),\n",
    "    \"44100\": (-75.5930, 36.2580),\n",
    "    \"44086\": (-75.4210, 36.0010),\n",
    "    \"44056\": (-75.7140, 36.2000),\n",
    "    \"44095\": (-75.3300, 35.7500),\n",
    "    \"41120\": (-75.2850, 35.2580),\n",
    "    \"41025\": (-75.4540, 35.0100),\n",
    "    \"41159\": (-76.9440, 34.2110),\n",
    "    \"41110\": (-77.7150, 34.1420),\n",
    "    \"41013\": (-77.7640, 33.4410),\n",
    "    \"41108\": (-78.0160, 33.7210),\n",
    "}\n",
    "\n",
    "\n",
    "def find_site_index(kp_coeffs, target_x, target_y, tolerance=1.0):\n",
    "    \"\"\"\n",
    "    Find the site index in kp_coeffs that matches the target coordinates.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    kp_coeffs : xarray.Dataset\n",
    "        The kp coefficients dataset\n",
    "    target_x : float\n",
    "        Target UTM x coordinate\n",
    "    target_y : float\n",
    "        Target UTM y coordinate\n",
    "    tolerance : float\n",
    "        Tolerance for coordinate matching (in meters)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    int\n",
    "        The site index that matches the coordinates\n",
    "    \"\"\"\n",
    "    # Get all site coordinates\n",
    "    site_x = kp_coeffs.utm_x.values\n",
    "    site_y = kp_coeffs.utm_y.values\n",
    "\n",
    "    # Calculate distances to all sites\n",
    "    distances = np.sqrt((site_x - target_x) ** 2 + (site_y - target_y) ** 2)\n",
    "\n",
    "    # Find the site with minimum distance\n",
    "    site_index = np.argmin(distances)\n",
    "\n",
    "    # Check if the closest site is within tolerance\n",
    "    if distances[site_index] > tolerance:\n",
    "        print(f\"Warning: Closest site is {distances[site_index]:.2f} meters away\")\n",
    "\n",
    "    return site_index\n",
    "\n",
    "\n",
    "def load_buoy_data(buoy_id, year=None):\n",
    "    \"\"\"\n",
    "    Load buoy data and return both the wave data and location coordinates.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    buoy_id : str\n",
    "        The buoy ID (e.g., '44100')\n",
    "    year : str, optional\n",
    "        The year to filter data for (default: None)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (buoy_waves, buoy_location, kp_coeffs)\n",
    "    \"\"\"\n",
    "    # Load buoy data\n",
    "    buoy_waves = pd.read_pickle(\n",
    "        f\"inputs/buoy_{buoy_id}_bulk_parameters.pkl\"\n",
    "    ).sort_index()\n",
    "    if year:\n",
    "        buoy_waves = buoy_waves.loc[year]\n",
    "    buoy_waves = buoy_waves.dropna(subset=[\"Hs_Buoy\", \"Tp_Buoy\", \"Dir_Buoy\"])\n",
    "\n",
    "    # Get buoy location (both UTM and WGS84)\n",
    "    buoy_location = buoys[buoy_id]\n",
    "\n",
    "    # Load kp coefficients\n",
    "    kp_coeffs = xr.open_dataset(\"outputs/kp_coefficients.nc\")\n",
    "\n",
    "    # Find the correct site index\n",
    "    site_index = find_site_index(kp_coeffs, buoy_location[0], buoy_location[1])\n",
    "\n",
    "    # Select the correct site\n",
    "    kp_coeffs = kp_coeffs.isel(site=[site_index])\n",
    "\n",
    "    return buoy_waves, buoy_location, kp_coeffs\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "buoy_id = \"41013\"  # Change this to use different buoys\n",
    "buoy_waves, buoy_location, kp_coeffs = load_buoy_data(buoy_id, \"2023\")\n",
    "\n",
    "# Print the coordinates for verification\n",
    "print(f\"Buoy {buoy_id} coordinates:\")\n",
    "print(f\"WGS84: {buoy_location[0]}, {buoy_location[1]}\")\n",
    "print(f\"\\nSelected kp_coeffs site coordinates:\")\n",
    "print(f\"{kp_coeffs.utm_x.values}, {kp_coeffs.utm_y.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import xarray as xr\n",
    "\n",
    "# # Load buoy data and kps\n",
    "\n",
    "# buoy_waves = pd.read_pickle(\"outputs/buoy_44088_bulk_parameters.pkl\").sort_index().loc[\"2022\"]\n",
    "\n",
    "# kp_coeffs = xr.open_dataset(\"outputs/kp_coefficients.nc\").isel(site=[-11])\n",
    "# kp_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-77.764]), array([33.441]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp_coeffs.utm_x.values, kp_coeffs.utm_y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offshore Spectrum\n",
    "\n",
    "> ‚ö†Ô∏è **NOTE:** If satellite correction was applied, ensure that 'satellite_correction=True'. The default value is False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.operations import transform_ERA5_spectrum\n",
    "\n",
    "model_parameters = pd.read_csv(\"CASES/swan_cases.csv\").to_dict(orient=\"list\")\n",
    "\n",
    "# Load interest spectra\n",
    "offshore_spectra, offshore_spectra_case = transform_ERA5_spectrum(\n",
    "    era5_spectrum=xr.open_dataset(\"inputs/superpoint_result_interpolated.nc\"),\n",
    "    subset_parameters=model_parameters,\n",
    "    available_case_num=kp_coeffs.case_num.values,\n",
    "    satellite_correction=True,\n",
    ")\n",
    "offshore_spectra_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bluemath_tk.waves.binwaves import reconstruc_spectra\n",
    "\n",
    "# First, ensure unique times in offshore_spectra_case\n",
    "_, unique_idx_offshore = np.unique(offshore_spectra_case.time, return_index=True)\n",
    "offshore_spectra_case = offshore_spectra_case.isel(time=unique_idx_offshore)\n",
    "\n",
    "# Then, ensure unique times in buoy_waves\n",
    "buoy_waves = buoy_waves[~buoy_waves.index.duplicated(keep=\"first\")]\n",
    "\n",
    "\n",
    "reconstructed_onshore_spectra = reconstruc_spectra(\n",
    "    offshore_spectra=offshore_spectra_case.sel(time=buoy_waves.index, method=\"nearest\"),\n",
    "    kp_coeffs=kp_coeffs,\n",
    "    num_workers=8,\n",
    ")\n",
    "reconstructed_onshore_spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check why for some years it fails due to NaNs in the reconstructed spectra\n",
    "from utils.plotting import plot_wave_series\n",
    "\n",
    "# First ensure all datasets have unique time values\n",
    "_, unique_idx_recon = np.unique(reconstructed_onshore_spectra.time, return_index=True)\n",
    "reconstructed_onshore_spectra = reconstructed_onshore_spectra.isel(\n",
    "    time=unique_idx_recon\n",
    ")\n",
    "\n",
    "_, unique_idx_offshore = np.unique(offshore_spectra.time, return_index=True)\n",
    "offshore_spectra = offshore_spectra.isel(time=unique_idx_offshore)\n",
    "\n",
    "# Make sure buoy_waves has unique indices (if not already done)\n",
    "buoy_waves = buoy_waves[~buoy_waves.index.duplicated(keep=\"first\")]\n",
    "\n",
    "# Now plot with the deduplicated datasets\n",
    "plot_wave_series(\n",
    "    buoy_data=buoy_waves,\n",
    "    binwaves_data=reconstructed_onshore_spectra.sel(\n",
    "        time=buoy_waves.index, method=\"nearest\"\n",
    "    )\n",
    "    .rename({\"kps\": \"efth\"})\n",
    "    .squeeze()\n",
    "    .spec,\n",
    "    offshore_data=offshore_spectra.sel(time=buoy_waves.index, method=\"nearest\").spec,\n",
    "    times=buoy_waves.index.values,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bluemath-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
