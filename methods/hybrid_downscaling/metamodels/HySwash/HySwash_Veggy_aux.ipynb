{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HySwash: A hybrid method for nearshore wave processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set BlueMath environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "import utils.plotting\n",
    "import bluemath_tk.topo_bathy.profiles\n",
    "from bluemath_tk.datamining.lhs import LHS\n",
    "from bluemath_tk.datamining.mda import MDA\n",
    "from bluemath_tk.waves.series import waves_dispersion \n",
    "from bluemath_tk.wrappers.swash.swash_wrapper import HySwashVeggyModelWrapper\n",
    "from bluemath_tk.core.io import load_model\n",
    "import xarray as xr\n",
    "\n",
    "root_dir = os.getcwd()\n",
    "#output_dir = \"/discos/rapido/outputVeggy\"\n",
    "output_dir = \"/lustre/geocean/DATA/hidronas1/valva/Veggy_topo_alba\"\n",
    "templates_dir = os.path.join(root_dir, \"templates\", \"VeggyBig\")\n",
    "export_dir = op.join(root_dir, \"HyVeggy_exported\")\n",
    "\n",
    "swash_model=load_model(op.join(export_dir, \"swash_model.pkl\"))\n",
    "postprocessed_output = xr.open_dataset(op.join(output_dir, \"output_postprocessed.nc\"))\n",
    "postprocessed_clean = xr.open_dataset(op.join(output_dir, \"output_postprocessed_clean.nc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build, run and postprocess cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swash_model.load_cases()\n",
    "#swash_model.build_cases()\n",
    "#swash_model.run_cases_in_background(launcher=\"serial\", num_workers=1)\n",
    "#swash_model.run_cases_bulk(launcher=\"sbatch --array=0-50 /home/grupos/geocean/valvanuz/HySwash/SlurmChy.sh\")\n",
    "#swash_model.monitor_cases()\n",
    "swash_model.monitor_cases(value_counts=\"cases\")\n",
    "#swash_model.monitor_cases(value_counts=\"simple\")\n",
    "\n",
    "swash_model=load_model(op.join(export_dir, \"swash_model.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_cases_str = \",\".join([str(i) for i in bad])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessed_output = swash_model.postprocess_cases(write_output_nc=True,overwrite_output=False, overwrite_output_postprocessed=False)\n",
    "#postprocessed_output = swash_model.postprocess_cases(output_vars=[\"Ru2\",\"Hrms\"])\n",
    "#postprocessed_output = swash_model.postprocess_cases(force=True,overwrite_output=False,overwrite_output_postprocessed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load postprocessed data from NetCDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/lustre/geocean/DATA/hidronas1/valva/Veggy_topo_alba/\"\n",
    "postprocessed_output = xr.open_dataset(op.join(output_dir, \"output_postprocessed.nc\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if data postprocessed contain Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 120 nodes_per_wavelength ok: 421 and bad 579\n",
    "ok=[]\n",
    "bad=[]\n",
    "for case_num in postprocessed_output.case_num.values:\n",
    "    postprocessed_case = postprocessed_output.sel(case_num=case_num)\n",
    "    #for var in postprocessed_case.data_vars:\n",
    "    for var in [\"Hrms\"]:\n",
    "        if postprocessed_case[var].isnull().values.any():\n",
    "            # print the variable name and the first occurrence of NaN\n",
    "            nan_indices = np.where(np.isnan(postprocessed_case[var].values))\n",
    "            bad.append(case_num)\n",
    "        else:\n",
    "            ok.append(case_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save bad to a pickle file\n",
    "import pickle\n",
    "with open(op.join(export_dir, \"bad_cases.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(bad, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new dataset with outputs that do not contain Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_clean=postprocessed_output.copy(deep=True)\n",
    "# get unique values of ok\n",
    "post_clean=post_clean.sel(case_num=ok)\n",
    "post_clean.to_netcdf(\n",
    "    os.path.join(output_dir, \"output_postprocessed_clean.nc\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Reconstruction: Principal Component Analysis (PCA) & Radial Basis Fucntions (RBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PCA and RBF models\n",
    "pca=load_model(\n",
    "        model_path=op.join(export_dir, \"pca_model.pkl\"),\n",
    "    )\n",
    "\n",
    "rbf=load_model(\n",
    "        model_path=op.join(export_dir, f\"rbf_model.pkl\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plotting import show_graph_for_all_vegetations\n",
    "\n",
    "depth = np.loadtxt(os.path.join(os.getcwd(), \"templates\", \"depth.bot\"))\n",
    "show_graph_for_all_vegetations(pca=pca, rbf=rbf, depth=depth, hs=2.0, hs_l0=0.02)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bluemath_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
